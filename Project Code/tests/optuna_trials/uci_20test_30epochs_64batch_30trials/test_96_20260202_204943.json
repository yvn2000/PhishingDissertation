{
    "trial_number": 15,
    "params": {
        "nConv": 2,
        "pool_0": 4,
        "filters_0": 64,
        "kernel_0": 5,
        "pool_1": 2,
        "filters_1": 192,
        "kernel_1": 3,
        "n_gru": 2,
        "gru_units_0": 192,
        "gru_dropout_0": 0.15818407706576187,
        "gru_rec_dropout_0": 0.16250777081009082,
        "gru_units_1": 64,
        "gru_dropout_1": 0.2885219472440962,
        "gru_rec_dropout_1": 0.24677348123171217,
        "n_dense": 1,
        "dense_units_0": 256,
        "dense_dropout_0": 0.2608685692472505
    },
    "best_val_accuracy": 0.9683400988578796,
    "batch_size": 64,
    "epochs": 30,
    "epochs_ran": 15,
    "model_structure": {
        "convolutional_layers": [
            {
                "n_filters": 64,
                "kernel_size": 5,
                "activation_function": "relu",
                "padding": true,
                "kernel_regularizer": "l2(1e-4)",
                "batch_normalization": true,
                "max_pooling_size": 4
            },
            {
                "n_filters": 192,
                "kernel_size": 3,
                "activation_function": "relu",
                "padding": true,
                "kernel_regularizer": "l2(1e-4)",
                "batch_normalization": true,
                "max_pooling_size": 0
            }
        ],
        "bigru_layers": [
            {
                "n_gru_units": 192,
                "return_sequences": true,
                "dropout": 0.15818407706576187,
                "recurrent_dropout": 0.16250777081009082,
                "attention": false,
                "dual_pooling": false
            },
            {
                "n_gru_units": 64,
                "return_sequences": false,
                "dropout": 0.2885219472440962,
                "recurrent_dropout": 0.24677348123171217,
                "attention": false,
                "dual_pooling": false
            }
        ],
        "dense_layers": [
            {
                "n_dense": 256,
                "activation_function": "relu",
                "kernel_regularizer": "l2(1e-4)",
                "batch_normalization": true,
                "dropout": 0.2608685692472505
            }
        ],
        "output_layer": {
            "n_dense": 1,
            "function": "sigmoid"
        }
    }
}